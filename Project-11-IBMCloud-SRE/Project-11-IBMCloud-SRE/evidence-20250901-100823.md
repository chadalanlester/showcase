# Project 4 Evidence (20250901-100823)

## Service URL
```
http://a4e1badd69ade4ab187558cd57eeb405-565001224.us-west-1.elb.amazonaws.com
```

## Endpoints
```
{"fact":"Golden Signals: latency, traffic, errors, saturation."}

ok
ok
```

## Objects
### Service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP                                                              PORT(S)        AGE   SELECTOR
trivia-api   LoadBalancer   172.20.206.24   a4e1badd69ade4ab187558cd57eeb405-565001224.us-west-1.elb.amazonaws.com   80:31439/TCP   78m   app=trivia-api

### Deployment
NAME         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                                                                    SELECTOR
trivia-api   2/2     2            2           78m   trivia-api   ghcr.io/chadalanlester/showcase/project-4-resilient-app:v20250901091607   app=trivia-api

### Pods
NAME                          READY   STATUS    RESTARTS   AGE   IP            NODE                                        NOMINATED NODE   READINESS GATES
trivia-api-54d84c4796-w27wj   1/1     Running   0          51m   10.10.1.183   ip-10-10-1-145.us-west-1.compute.internal   <none>           <none>
trivia-api-54d84c4796-wxdh2   1/1     Running   0          51m   10.10.2.23    ip-10-10-2-87.us-west-1.compute.internal    <none>           <none>

## HPA
NAME             REFERENCE               TARGETS       MINPODS   MAXPODS   REPLICAS   AGE
trivia-api-hpa   Deployment/trivia-api   cpu: 1%/60%   2         6         2          78m

Name:                                                  trivia-api-hpa
Namespace:                                             resilient
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Mon, 01 Sep 2025 08:50:26 -0700
Reference:                                             Deployment/trivia-api
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  1% (1m) / 60%
Min replicas:                                          2
Max replicas:                                          6
Deployment pods:                                       2 current / 2 desired
Conditions:
  Type            Status  Reason            Message
  ----            ------  ------            -------
  AbleToScale     True    ReadyForNewScale  recommended size matches current size
  ScalingActive   True    ValidMetricFound  the HPA was able to successfully calculate a replica count from cpu resource utilization (percentage of request)
  ScalingLimited  True    TooFewReplicas    the desired replica count is less than the minimum replica count
Events:
  Type     Reason                        Age                 From                       Message
  ----     ------                        ----                ----                       -------
  Warning  FailedComputeMetricsReplicas  75m (x12 over 77m)  horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu resource metric value: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Warning  FailedGetResourceMetric       67m (x41 over 77m)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Warning  FailedComputeMetricsReplicas  61m (x12 over 63m)  horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu resource metric value: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Warning  FailedGetResourceMetric       48m (x61 over 63m)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Normal   SuccessfulRescale             43m                 horizontal-pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
  Normal   SuccessfulRescale             42m                 horizontal-pod-autoscaler  New size: 6; reason: cpu resource utilization (percentage of request) above target
  Normal   SuccessfulRescale             34m                 horizontal-pod-autoscaler  New size: 2; reason: All metrics below target


## Top Pods (CPU/Memory)
NAME                          CPU(cores)   MEMORY(bytes)
trivia-api-54d84c4796-w27wj   1m           52Mi
trivia-api-54d84c4796-wxdh2   1m           52Mi

## ArgoCD Application
NAME               SYNC STATUS   HEALTH STATUS   REVISION                                   PROJECT
resilient-trivia   OutOfSync     Healthy         0f1020b417f599da5b9ebdf6c19bd2d83692a8ae   resilient

### ArgoCD Application Describe (first 120 lines)
Name:         resilient-trivia
Namespace:    argocd
Labels:       <none>
Annotations:  <none>
API Version:  argoproj.io/v1alpha1
Kind:         Application
Metadata:
  Creation Timestamp:  2025-09-01T15:46:32Z
  Generation:          90
  Resource Version:    21279
  UID:                 646f0a6b-4d03-4cb4-914d-5382958881d8
Operation:
  Initiated By:
    Automated:  true
  Retry:
    Limit:  5
  Sync:
    Prune:     true
    Revision:  0f1020b417f599da5b9ebdf6c19bd2d83692a8ae
    Sync Options:
      CreateNamespace=true
Spec:
  Destination:
    Namespace:  resilient
    Server:     https://kubernetes.default.svc
  Project:      resilient
  Source:
    Directory:
      Jsonnet:
      Recurse:        true
    Path:             project-4-resilient-app/k8s/base
    Repo URL:         https://github.com/chadalanlester/showcase.git
    Target Revision:  main
  Sync Policy:
    Automated:
      Prune:      true
      Self Heal:  true
    Sync Options:
      CreateNamespace=true
Status:
  Controller Namespace:  argocd
  Health:
    Last Transition Time:  2025-09-01T16:19:32Z
    Status:                Healthy
  Operation State:
    Finished At:  2025-09-01T17:05:51Z
    Message:      one or more synchronization tasks are not valid due to application controller sync timeout. Retrying attempt #5 at 5:07PM.
    Operation:
      Initiated By:
        Automated:  true
      Retry:
        Limit:  5
      Sync:
        Prune:     true
        Revision:  0f1020b417f599da5b9ebdf6c19bd2d83692a8ae
        Sync Options:
          CreateNamespace=true
    Phase:        Running
    Retry Count:  5
    Started At:   2025-09-01T17:03:21Z
    Sync Result:
      Resources:
        Group:       kustomize.config.k8s.io
        Kind:        Kustomization
        Message:     The Kubernetes API could not find kustomize.config.k8s.io/Kustomization for requested resource resilient/. Make sure the "Kustomization" CRD is installed on the destination cluster.
        Name:
        Namespace:   resilient
        Status:      SyncFailed
        Sync Phase:  Sync
        Version:     v1beta1
        Group:       monitoring.coreos.com
        Kind:        PrometheusRule
        Message:     The Kubernetes API could not find monitoring.coreos.com/PrometheusRule for requested resource monitoring/trivia-api-rules. Make sure the "PrometheusRule" CRD is installed on the destination cluster.
        Name:        trivia-api-rules
        Namespace:   monitoring
        Status:      SyncFailed
        Sync Phase:  Sync
        Version:     v1
      Revision:      0f1020b417f599da5b9ebdf6c19bd2d83692a8ae
      Source:
        Directory:
          Jsonnet:
          Recurse:         true
        Path:              project-4-resilient-app/k8s/base
        Repo URL:          https://github.com/chadalanlester/showcase.git
        Target Revision:   main
  Reconciled At:           2025-09-01T17:05:51Z
  Resource Health Source:  appTree
  Resources:
    Kind:       Service
    Name:       trivia-api
    Namespace:  resilient
    Status:     OutOfSync
    Version:    v1
    Group:      apps
    Kind:       Deployment
    Name:       trivia-api
    Namespace:  resilient
    Status:     OutOfSync
    Version:    v1
    Group:      autoscaling
    Kind:       HorizontalPodAutoscaler
    Name:       trivia-api-hpa
    Namespace:  resilient
    Status:     OutOfSync
    Version:    v2
    Group:      kustomize.config.k8s.io
    Kind:       Kustomization
    Namespace:  resilient
    Status:     OutOfSync
    Version:    v1beta1
    Group:      monitoring.coreos.com
    Kind:       PrometheusRule
    Name:       trivia-api-rules
    Namespace:  monitoring
    Status:     OutOfSync
    Version:    v1
    Group:      policy
    Kind:       PodDisruptionBudget
    Name:       trivia-api-pdb

## Chaos: delete one pod
### Before
NAME                          READY   STATUS    RESTARTS   AGE   IP            NODE                                        NOMINATED NODE   READINESS GATES
trivia-api-54d84c4796-w27wj   1/1     Running   0          51m   10.10.1.183   ip-10-10-1-145.us-west-1.compute.internal   <none>           <none>
trivia-api-54d84c4796-wxdh2   1/1     Running   0          51m   10.10.2.23    ip-10-10-2-87.us-west-1.compute.internal    <none>           <none>

### Action
pod "trivia-api-54d84c4796-w27wj" force deleted from resilient namespace
Killed pod: trivia-api-54d84c4796-w27wj in ns=resilient

### After (rollout and pods)
Waiting for deployment "trivia-api" rollout to finish: 1 of 2 updated replicas are available...
deployment "trivia-api" successfully rolled out
NAME                          READY   STATUS    RESTARTS   AGE   IP            NODE                                        NOMINATED NODE   READINESS GATES
trivia-api-54d84c4796-mw2xv   1/1     Running   0          11s   10.10.1.189   ip-10-10-1-145.us-west-1.compute.internal   <none>           <none>
trivia-api-54d84c4796-wxdh2   1/1     Running   0          52m   10.10.2.23    ip-10-10-2-87.us-west-1.compute.internal    <none>           <none>

## Metrics API
v1.metrics.eks.amazonaws.com      kube-system/eks-extension-metrics-api   True        118m
v1beta1.metrics.k8s.io            kube-system/metrics-server              True        49m
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
metrics-server   1/1     1            1           49m

## GitHub Actions: Resilience Checks (latest)
